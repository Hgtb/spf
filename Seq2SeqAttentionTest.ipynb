{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run on GPU server\n",
    "import sys\n",
    "sys.path.append(\"../StockPriceForecast/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available :  True\n",
      "Cuda num :  1\n",
      "Current cuda index :  0\n",
      "Current cuda name :  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "print(\"Cuda is available : \", torch.cuda.is_available())\n",
    "print(\"Cuda num : \", torch.cuda.device_count())  # gpu数量\n",
    "print(\"Current cuda index : \", torch.cuda.current_device())\n",
    "print(\"Current cuda name : \", torch.cuda.get_device_name(0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All days :  2994\n",
      "target_data :  torch.Size([30, 1440, 1])\n",
      "Train days :  (2274, 1440, 10)\n",
      "Validation days ;  (720, 1440, 10)\n",
      "Test days :  (720, 1440, 10)\n"
     ]
    }
   ],
   "source": [
    "from libs import *\n",
    "dataPath = \"../StockPriceForecast/dataSet/data/marketData/data.nc\"\n",
    "data_len = DataLength(dataPath)\n",
    "print(\"All days : \", data_len)\n",
    "input_days = 360\n",
    "predict_days = 30\n",
    "test_predict_len = 360  # 预测360天\n",
    "train_dataSet = DataSet(dataPath=dataPath, isel=[0, data_len - input_days - test_predict_len],\n",
    "                        encoderDecoderParameter=\"close\",\n",
    "                        targetDataParameter=\"close\")\n",
    "train, target = train_dataSet[0]\n",
    "print(\"Train days : \", train_dataSet.data.shape)\n",
    "validation_dataSet = DataSet(dataPath=dataPath, isel=[data_len - (input_days + 2 * test_predict_len), data_len - test_predict_len])\n",
    "print(\"Validation days ; \", validation_dataSet.data.shape)\n",
    "test_dataSet = DataSet(dataPath=dataPath, isel=[data_len - (input_days + test_predict_len), data_len])\n",
    "print(\"Test days : \", test_dataSet.data.shape)\n",
    "\n",
    "train_dataLoader = DataLoader(train_dataSet)\n",
    "validation_dataLoader = DataLoader(validation_dataSet)\n",
    "test_dataLoader = DataLoader(test_dataSet)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../StockPriceForecast/Models/spf_L1_5e-05_1_100.pth\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "models_store_path = \"../StockPriceForecast/Models/\"\n",
    "days_num = 100\n",
    "loss_function_name = \"L1\"\n",
    "lr = 0.00005\n",
    "num_epochs = 1\n",
    "model_name = f\"spf_{loss_function_name}_{lr}_{num_epochs}_{days_num}.pth\"\n",
    "model_store_path = join(models_store_path, model_name)\n",
    "train_dataSet = train_dataSet.isel(0, 390 + days_num -1)\n",
    "train_dataLoader = DataLoader(train_dataSet)\n",
    "print(model_store_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 training:   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_data :  torch.Size([30, 1440, 10])\n",
      "enc_input[-1].unsqueeze(dim=0) :  torch.Size([1, 1, 14400])\n",
      "dec_input[:-1]] :  torch.Size([29, 1440, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 1 but got size 1440 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_9139/3844490407.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m                          \u001B[0mnum_layers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m                          dropout=0.1)\n\u001B[0;32m---> 10\u001B[0;31m model = train_Seq2SeqAttention(model=model,\n\u001B[0m\u001B[1;32m     11\u001B[0m                                \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m                                \u001B[0mdataLoader\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain_dataLoader\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/../StockPriceForecast/libs/modules/Seq2SeqAttention.py\u001B[0m in \u001B[0;36mtrain_Seq2SeqAttention\u001B[0;34m(model, device, lr, loss_function_name, num_epochs, dataLoader, init_weights)\u001B[0m\n\u001B[1;32m    114\u001B[0m             \u001B[0mY\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 116\u001B[0;31m             \u001B[0mY_hat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattention_weight_seq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menc_input\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdec_input\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    117\u001B[0m             \u001B[0ml\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mY_hat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Y : torch.Size([30, 1440]) -> torch.Size([30, 1, 1440])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    118\u001B[0m             \u001B[0ml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 有bug\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/../StockPriceForecast/libs/modules/Seq2SeqAttention.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, enc_input, dec_input, steps)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menc_input\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdec_input\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menc_input\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msteps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/../StockPriceForecast/libs/modules/Seq2SeqAttention.py\u001B[0m in \u001B[0;36mtrain_module\u001B[0;34m(self, enc_input, dec_input)\u001B[0m\n\u001B[1;32m     47\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"enc_input[-1].unsqueeze(dim=0) : \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menc_input\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"dec_input[:-1]] : \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdec_input\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m         \u001B[0mdec_input\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0menc_input\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdec_input\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 使用Encoder的最后一个输入作为开始(向前移动一步)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0mdecoder_output\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecoder_attention_weights\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecoder_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdec_input\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecoder_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclean_attention_weights\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 0. Expected size 1 but got size 1440 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "from libs.modules import *\n",
    "from libs import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "model = Seq2SeqAttention(input_size=14400,\n",
    "                         hidden_size=4096,\n",
    "                         output_size=1440,\n",
    "                         num_layers=4,\n",
    "                         dropout=0.1)\n",
    "model = train_Seq2SeqAttention(model=model,\n",
    "                               device=device,\n",
    "                               dataLoader=train_dataLoader,\n",
    "                               loss_function_name=loss_function_name,\n",
    "                               lr=lr,\n",
    "                               num_epochs=num_epochs)\n",
    "torch.save(model, model_store_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validation_dataLoader.isel(0, 1)\n",
    "predicts, targets, attention_weights = eval_Seq2SeqAttention(model=model,\n",
    "                                                    dataLoader=validation_dataLoader,\n",
    "                                                    steps=30,\n",
    "                                                    device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}